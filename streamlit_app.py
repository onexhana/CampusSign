import streamlit as st
import numpy as np
import tempfile
import os
import cv2
import json
import torch
import shutil

from app.extractor import extract_keypoints_from_video
from app.preprocess import convert_json_to_sequence
from app.model import load_model

# ì„¤ì •
MODEL_PATH = "trained_model.pt"
LABEL_MAP_PATH = "app/label_mapping.json"
SENTENCE_TEMPLATE_PATH = "app/sentence_templates.json"
INPUT_SIZE = 225
HIDDEN_SIZE = 128

# ëª¨ë¸ ë¡œë”©
with open(LABEL_MAP_PATH, encoding="utf-8") as f:
    label_mapping = json.load(f)

label_set = set()
for v in label_mapping.values():
    label_set.update(v) if isinstance(v, list) else label_set.add(v)
label_list = sorted(label_set)
label2idx = {label: i for i, label in enumerate(label_list)}
idx2label = {i: label for label, i in label2idx.items()}
num_classes = len(label2idx)

model = load_model(MODEL_PATH, INPUT_SIZE, HIDDEN_SIZE, num_classes)

# Streamlit UI
st.title("ğŸ“¹ CampusSign ì‹¤ì‹œê°„ ìˆ˜ì–´ ë²ˆì—­ê¸°")
st.write("ğŸŸ¢ ì›¹ìº /ì˜ìƒ ì…ë ¥ â†’ ìˆ˜ì–´ ë‹¨ì–´ ì¸ì‹ â†’ ìì—°ì–´ ë¬¸ì¥ ì¶œë ¥")

mode = st.radio("ì…ë ¥ ë°©ì‹ ì„ íƒ", ["ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ", "ğŸ“¸ ì‹¤ì‹œê°„ ì›¹ìº  (ë°ëª¨ìš©)"])

# í…œí”Œë¦¿ ë¡œë”©
with open(SENTENCE_TEMPLATE_PATH, encoding="utf-8") as f:
    templates = json.load(f)

predicted_words = []

def predict_from_video(video_path):
    json_path = video_path.replace(".mp4", ".json").replace(".mkv", ".json")
    try:
        extract_keypoints_from_video(video_path, json_path)
    except Exception as e:
        st.error(f"âŒ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

    if not os.path.exists(json_path):
        st.error("âŒ .json íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    try:
        with open(json_path, encoding='utf-8') as f:
            kp_data = json.load(f)
        sequence_array = convert_json_to_sequence(kp_data)
        if sequence_array is None:
            st.error("âŒ í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë³€í™˜ ì‹¤íŒ¨.")
            return None
    except Exception as e:
        st.error(f"âŒ JSON ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

    try:
        x = torch.tensor(sequence_array[0], dtype=torch.float32).unsqueeze(0)
        with torch.no_grad():
            y_pred = model(x)
            pred_label = idx2label[torch.argmax(y_pred).item()]
            return pred_label
    except Exception as e:
        st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ ëª¨ë“œ
if mode == "ğŸ¥ ì˜ìƒ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ìˆ˜ì–´ ì˜ìƒ ì—…ë¡œë“œ (.mp4, .mkv)", type=["mp4", "mkv"])
    if uploaded_file:
        suffix = os.path.splitext(uploaded_file.name)[-1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_video:
            shutil.copyfileobj(uploaded_file, temp_video)
            temp_path = temp_video.name

        pred = predict_from_video(temp_path)
        if pred:
            st.success(f"ğŸ§  ì˜ˆì¸¡ëœ ë‹¨ì–´: **{pred}**")
            sentence = templates.get(pred)
            if sentence:
                st.info(f"ğŸ“ ì¶œë ¥ ë¬¸ì¥: {sentence}")
            else:
                st.warning(f"â„¹ï¸ '{pred}'ì— ëŒ€í•œ ë¬¸ì¥ í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("â— ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ“¸ ì‹¤ì‹œê°„ ì›¹ìº  ëª¨ë“œ
elif mode == "ğŸ“¸ ì‹¤ì‹œê°„ ì›¹ìº  (ë°ëª¨ìš©)":
    st.warning("âš ï¸ ì´ ëª¨ë“œëŠ” ë°ìŠ¤í¬íƒ‘ì—ì„œë§Œ ì‘ë™í•˜ë©°, Streamlit Cloudì—ì„œëŠ” ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    run_webcam = st.button("ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œì‘")
    if run_webcam:
        st.info("ğŸ“¸ ì›¹ìº ì„ ì—´ê³  í•œ ë‹¨ì–´ ìˆ˜ì–´ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”. ì˜ˆ: 'ì¶œì„', 'ê³¼ì œ' ë“±")
        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            st.error("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì•±ì´ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            frame_list = []
            for _ in range(60):  # ì•½ 2ì´ˆê°„ í”„ë ˆì„ ìˆ˜ì§‘
                ret, frame = cap.read()
                if not ret:
                    st.error("ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                frame = cv2.flip(frame, 1)
                frame_list.append(frame)
            cap.release()

            if frame_list:
                temp_path = os.path.join(tempfile.gettempdir(), "webcam_clip.mp4")
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                out = cv2.VideoWriter(temp_path, fourcc, 15.0, (frame.shape[1], frame.shape[0]))
                for frame in frame_list:
                    out.write(frame)
                out.release()

                pred = predict_from_video(temp_path)
                if pred:
                    predicted_words.append(pred)
                    st.success(f"ğŸ§  ì˜ˆì¸¡ëœ ë‹¨ì–´: **{pred}**")
                    st.write(f"ğŸ§© í˜„ì¬ ì¸ì‹ëœ ë‹¨ì–´ë“¤: `{predicted_words}`")
                    if pred in templates:
                        st.info(f"ğŸ“ ì¶œë ¥ ë¬¸ì¥ ì˜ˆì‹œ: {templates[pred]}")
                    else:
                        st.warning(f"â„¹ï¸ '{pred}'ì— ëŒ€í•œ ë¬¸ì¥ í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("â— ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
